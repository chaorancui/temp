# 数学

# 概率论

## 归一化和标准化

最小-最大归一化（Min-Max Normalization）和标准化（Standardization）是两种常见的特征缩放技术，它们在机器学习和数据预处理中有不同的用途和特点。

### 最小-最大归一化（Min-Max Normalization）

**定义**：最小-最大归一化将数据缩放到一个固定范围，通常是0到1，或者-1到1。

**公式**：$x' = \frac{x - x_{min}}{x_{max} - x_{min}}$

其中，$x$ 是原始数据，$x_{min}$ 和 $x_{max}$ 分别是数据集中的最小值和最大值，$x′$ 是归一化后的数据。

**特点**：

- **范围固定**：数据被缩放到一个固定范围内。
- **易受异常值影响**：如果数据中存在异常值，最小值和最大值会被拉大，从而影响归一化结果。
- **适用场景**：适用于特征范围已知且固定的情况，如图像像素值的归一化（0到255之间）。

**示例代码**：

```python
import numpy as np

# 生成数据
data = np.array([1, 2, 3, 4, 5])
x_min = np.min(data)
x_max = np.max(data)

# 进行最小-最大归一化
data_normalized = (data - x_min) / (x_max - x_min)
print(data_normalized)
```

### 标准化（Standardization）

**定义**：标准化将数据转换为均值为0、标准差为1的正态分布。

**公式**： $x' = \frac{x - \mu}{\sigma}$

其中，$x$ 是原始数据，$\mu$ 是数据的均值，$\sigma$ 是数据的标准差，$x′$ 是标准化后的数据。

**特点**：

- **无固定范围**：标准化后的数据没有固定的范围，但会符合标准正态分布。
- **减少异常值影响**：标准化减少了异常值对数据分布的影响，因为它基于数据的均值和标准差。
- **适用场景**：适用于数据分布不确定，且可能具有不同量级的情况，如机器学习算法中的特征缩放（例如SVM、KNN）。

**示例代码**：

```python
import numpy as np

# 生成数据
data = np.array([1, 2, 3, 4, 5])
mu = np.mean(data)
sigma = np.std(data)

# 进行标准化
data_standardized = (data - mu) / sigma
print(data_standardized)
```

### 区别总结

| 特点       | 最小-最大归一化                              | 标准化                        |
| ---------- | -------------------------------------------- | ----------------------------- |
| 公式       | $x' = \frac{x - x_{min}}{x_{max} - x_{min}}$ | $x' = \frac{x - \mu}{\sigma}$ |
| 范围       | 固定（通常是0到1）                           | 无固定范围                    |
| 异常值影响 | 易受影响                                     | 影响较小                      |
| 适用场景   | 特征范围已知且固定                           | 数据分布不确定或不同量级      |

这两种方法在实际应用中有不同的优缺点，选择哪种方法取决于具体的应用场景和数据特性 。

## 变量、协变量

在统计学和数据分析中，“变量”和“协变量”是两个常用的术语。虽然它们都涉及数据中的数值或类别，但它们在具体含义和应用上有所不同。以下是对变量和协变量的详细解释和它们之间的区别。

### 变量（Variable）

变量是指数据集中可以变化和测量的任何属性或特征。在统计学和数据分析中，变量可以分为以下几类：

1. **自变量（Independent Variable）**：
   - 也称为预测变量或解释变量。
   - 这些是研究中可以操控或选择的变量。
   - 例子：在一个关于肥料对植物生长影响的实验中，肥料的类型和数量就是自变量。
2. **因变量（Dependent Variable）**：
   - 也称为响应变量或结果变量。
   - 这些是研究中受到自变量影响的变量。
   - 例子：在上述实验中，植物的生长高度就是因变量。
3. **控制变量（Control Variable）**：
   - 这些变量需要保持恒定，以确保研究的有效性。
   - 例子：在植物生长实验中，光照和水分应该是控制变量。

### 协变量（Covariate）

协变量是指在统计模型中包含的额外变量，这些变量可能与研究中的自变量和因变量都有关系。协变量的主要作用是控制其他可能影响因变量的因素，以提高模型的精度和解释力。协变量常用于回归分析和实验设计中。

- 例子：在一个研究体重与血压关系的研究中，年龄和性别可能是协变量，因为它们也会影响血压。

### 变量和协变量的区别

1. **目的和角色**：
   - **变量**：通常是指自变量和因变量，直接涉及到研究的主要问题或假设。
   - **协变量**：是那些可能影响因变量但不是研究主要关注点的变量，主要用于控制其他影响因素。
2. **在模型中的作用**：
   - **自变量**：在模型中作为预测或解释因变量的主要因素。
   - **因变量**：在模型中作为主要结果或响应。
   - **协变量**：在模型中作为控制因素，用于消除混淆或提高模型的精确度。
3. **实例应用**：
   - **变量**：在一个实验中，如果我们研究药物剂量对病人康复时间的影响，药物剂量是自变量，康复时间是因变量。
   - **协变量**：如果我们考虑病人的年龄和初始健康状况对康复时间的影响，这些因素就是协变量。

### 总结

- **变量**是指研究中**可以变化和测量的任何属性或特征**，包括自变量（独立变量）、因变量（依赖变量）和控制变量。
- **协变量**是指在统计模型中包含的**额外变量**，用于**控制其他可能影响因变量的因素**，以提高模型的精度和解释力。

理解这两者的区别和应用，对于设计有效的实验和建立准确的统计模型非常重要。



# 线性代数

## 仿射变换

仿射变换是指一种**保持直线平行性质的几何变换**，它包括**平移、旋转、缩放和剪切**等操作。在二维空间中，一个仿射变换可以用一个非奇异的二阶矩阵和一个平移向量来描述，通常表示为：

$T(\mathbf{x}) = A \mathbf{x} + \mathbf{b}$

其中，$\mathbf{x}$ 是原始点的坐标向量，$A$ 是一个 2x2 的矩阵，$\mathbf{b}$ 是一个二维平移向量。

### 1. 平移变换 (Translation)

平移变换是将所有点沿某一方向移动一个固定距离。二维平移变换可以表示为：

$$T(\mathbf{x}) = \mathbf{x} + \mathbf{b}$$

其中，$\mathbf{x}$ 是原始点的坐标向量，$\mathbf{b}$ 是平移向量。

### 2. 旋转变换 (Rotation)

旋转变换是将所有点绕一个固定点旋转一定角度。二维旋转变换可以表示为：

$$R(\mathbf{x}) = \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix} \mathbf{x}$$

其中，$\thetaθ$ 是旋转角度。

### 3. 缩放变换 (Scaling)

缩放变换是按比例放大或缩小所有点。二维缩放变换可以表示为：

$$S(\mathbf{x}) = \begin{pmatrix} s_x & 0 \\ 0 & s_y \end{pmatrix} \mathbf{x}$$

其中，$s_x$ $s_y$ 分别是 x 和 y 方向的缩放因子。

### 4. 剪切变换 (Shear)

剪切变换是将所有点沿某一方向按比例移动，使图形倾斜。二维剪切变换可以表示为：

$$H(\mathbf{x}) = \begin{pmatrix} 1 & k_x \\ k_y & 1 \end{pmatrix} \mathbf{x}$$

其中，$k_x$ 和 $k_y$ 分别是 x 和 y 方向的剪切因子。

### 5. 仿射变换 (Affine Transformation)

仿射变换是包括上述所有变换的一种综合变换，它可以保持线的平行性。二维仿射变换可以表示为：

$$A(\mathbf{x}) = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{pmatrix} \mathbf{x} + \begin{pmatrix} b_1 \\ b_2 \end{pmatrix}$$

### 6. 齐次变换 (Homogeneous Transformation)

齐次变换是一种在项目空间中表示变换的方法，通过引入齐次坐标，可以将仿射变换表示为矩阵乘法，从而统一各种变换。三维齐次变换表示为：

$$T(\mathbf{x}) = \begin{pmatrix} A & \mathbf{b} \\ 0 & 1 \end{pmatrix} \mathbf{x}$$

其中，$A$ 是一个 3x3 的矩阵，$\mathbf{b}$ 是平移向量，$\mathbf{x}$ 是齐次坐标向量。

通过这些变换，可以灵活地操纵图形和图像，实现各种效果。



# 工程概念

## numpy 数组中轴

### 数组形状与轴维度的关系:

- 数组的形状（shape）描述了每个轴的维度。对于形状为 `(m, n)` 的二维数组：
  - `m` 表示 `axis 0` 上的元素数量（**即行数**），沿着这个轴可以访问不同的行。
  - `n` 表示 `axis 1` 上的元素数量（**即列数**），沿着这个轴可以访问不同的列。
- 在更高维的数组中，每个维度对应于特定的轴，形状的每个数字表示相应轴上的元素数量。

### 举例说明

- 一维数组:
  - `a = np.array([1, 2, 3, 4])`
  - 形状为 `(4,)`，表示这个数组只有一个轴（`axis 0`），该轴上有 4 个元素。
- 二维数组:
  - `b = np.array([[1, 2, 3], [4, 5, 6]])`
  - 形状为 `(2, 3)`，表示这个数组有两个轴：
    - `axis 0` 有 2 个元素（即有 2 行）。
    - `axis 1` 有 3 个元素（即每行有 3 列）。
- 三维数组:
  - `c = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])`
  - 形状为 `(2, 2, 3)`，表示这个数组有三个轴：
    - `axis 0` 有 2 个元素（即最外层的两个矩阵）。
    - `axis 1` 有 2 个元素（即每个矩阵中的两行）。
    - `axis 2` 有 3 个元素（即每行中的三个值）。

### 轴的意义与作用

#### 1. **数据处理**

- 在进行操作时，指定轴可以控制操作沿着哪个维度进行。例如，求和、平均、最大值、最小值等操作可以沿特定轴进行，得到不同的结果。
- 示例: 对二维数组 A 进行操作：
  - `np.sum(A, axis=0)`: 沿着轴0求和（压缩行），结果是对每一列求和。
  - `np.sum(A, axis=1)`: 沿着轴1求和（压缩列），结果是对每一行求和。

#### 2. **数据表示**

- 轴提供了理解数据形状和结构的途径。在多维数据中，轴决定了数据的排列方式。例如，在图像处理中，常见的图像张量通常是 `(height, width, channels)`，其中 `height` 对应于轴0，`width` 对应于轴1，`channels` 对应于轴2。

#### 3. **广播机制**

- 轴的概念在广播机制中也很重要。广播允许不同形状的数组在一起进行运算时，沿某个轴自动扩展维度以适配另一个数组。

# matlab 与 numpy 中的轴

### MATLAB 中数组的轴

> **每新增一个轴，原来的轴保持不变，新增的轴变为新的维度，看起来轴是在尾部新增的。**

MATLAB 中的数组是**列优先的**（column-major order），轴的编号从 1 开始。多维数组中的轴表示如下：

- **第1轴 (axis 1)**: 行方向（row），即沿着第一个维度变化。
- **第2轴 (axis 2)**: 列方向（column），即沿着第二个维度变化。
- **第3轴 (axis 3)**: 第三维度方向，依此类推。

例如，一个 $3 \times 4 \times 5$ 的数组：

- 第1轴（axis 1）长度为3（行数）。
- 第2轴（axis 2）长度为4（列数）。
- 第3轴（axis 3）长度为5。

### NumPy 中数组的轴

> **新增的轴总是添加在最前面，变成 0 轴，原来的轴依次加 1。**

NumPy 中的数组是**行优先的**（row-major order），轴的编号从 0 开始。多维数组中的轴表示如下：

- **第0轴 (axis 0)**: 行方向（row），即沿着第一个维度变化。
- **第1轴 (axis 1)**: 列方向（column），即沿着第二个维度变化。
- **第2轴 (axis 2)**: 第三维度方向，依此类推。

例如，一个形状为 `(3, 4, 5)` 的 NumPy 数组：

- 第0轴（axis 0）长度为3（行数）。
- 第1轴（axis 1）长度为4（列数）。
- 第2轴（axis 2）长度为5。

### 总结

- MATLAB 轴的编号从 **1** 开始，NumPy 轴的编号从 **0** 开始。
- MATLAB 的第`n`轴对应 NumPy 的第 `n-1` 轴。

举个例子：

- 在 MATLAB 中，对一个二维数组 `A`，`A(2, :)` 取第二行数据，对应 NumPy 中的 `A[1, :]`。
- 在 MATLAB 中，`sum(A, 2)` 是沿着列（第2轴）求和，对应 NumPy 中的 `np.sum(A, axis=1)`。

## numpy 中 axis=-1

在NumPy中，`axis=-1`表示数组的最后一个轴。这是一种便捷的方式来引用数组的最后一个维度，而不需要知道数组具体有多少维。

- 对于一维数组，`axis=-1`等同于`axis=0`
- 对于二维数组，`axis=-1`等同于`axis=1`
- 对于三维数组，`axis=-1`等同于`axis=2`
- 以此类推...

假设我们有以下数组：

```python
import numpy as np

# 创建一个3x4x5的数组
arr = np.array([[[1, 2, 3, 4, 5],
                 [6, 7, 8, 9, 10],
                 [11, 12, 13, 14, 15],
                 [16, 17, 18, 19, 20]],

                [[21, 22, 23, 24, 25],
                 [26, 27, 28, 29, 30],
                 [31, 32, 33, 34, 35],
                 [36, 37, 38, 39, 40]],

                [[41, 42, 43, 44, 45],
                 [46, 47, 48, 49, 50],
                 [51, 52, 53, 54, 55],
                 [56, 57, 58, 59, 60]]])
```

这个数组的形状是 `(3, 4, 5)`，即有 3 个矩阵，每个矩阵有 4 行 5 列。

如果我们对这个数组沿着 `axis=-1` 进行求和：

```python
sum_along_last_axis = np.sum(arr, axis=-1)
print(sum_along_last_axis)
```

输出将是一个形状为 `(3, 4)` 的数组：

```python
[[ 15  40  65  90]
 [115 140 165 190]
 [215 240 265 290]]
```

**详细解释：**

- **原始数组形状为 `(3, 4, 5)`**，表示有 3 个 4x5 的矩阵。
- **`axis=-1`** 表示最后一个轴（即每个 5 元素的列），沿着这个轴进行求和。
- 求和的结果是在每个 5 个元素的集合上进行的，因此原始的 `(3, 4, 5)` 数组变成了 `(3, 4)` 数组，最后一个轴消失，剩下的元素是沿着最后一个轴求和的结果。

## numpy 中多个轴做规约

### 示例

假设我们有一个三维数组，我们想沿着最后两个轴计算均值。

```python
import numpy as np

# 创建一个形状为 (2, 3, 4) 的三维数组
arr = np.array([[[1, 2, 3, 4],
                 [5, 6, 7, 8],
                 [9, 10, 11, 12]],

                [[13, 14, 15, 16],
                 [17, 18, 19, 20],
                 [21, 22, 23, 24]]])

# 沿着轴1和轴2计算均值
mean_across_axes = np.mean(arr, axis=(1, 2))
print("Mean across axis 1 and 2:\n", mean_across_axes)
```

### 解释

- **输入数组 `arr`** 的形状为 `(2, 3, 4)`，表示有 2 个 3x4 的矩阵。
- **`axis=(1, 2)`** 表示我们希望沿着第二个和第三个轴（即每个矩阵的行和列）计算均值。

### 结果

```python
Mean across axis 1 and 2:
 [ 6.5 18.5]
```

#### 结果解释：

- 对于第一个矩阵（形状 `(3, 4)`），其元素的均值为 6.5。
- 对于第二个矩阵，其元素的均值为 18.5。
- 结果是一个一维数组，形状为 `(2,)`，每个元素对应于原数组中沿着指定轴计算的均值。

### 更多示例

1. **计算二维数组中最后两个轴的均值**：

   ```python
   arr = np.random.rand(4, 5, 6)
   mean_across_last_two_axes = np.mean(arr, axis=(-2, -1))
   print("Mean across last two axes:\n", mean_across_last_two_axes)
   ```

   - 此例子中，`axis=(-2, -1)` 表示沿着倒数第二和最后一个轴（即二维数组的行和列）计算均值。

2. **保持原维度**：

   ```python
   mean_with_keepdims = np.mean(arr, axis=(1, 2), keepdims=True)
   print("Mean with keepdims:\n", mean_with_keepdims)
   ```

   - 设置 `keepdims=True` 时，输出数组保持原维度，只是沿着指定轴计算的均值位置的维度被压缩为 1。
