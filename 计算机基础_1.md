[toc]

## IEEE754 标准: 浮点数存储

> <https://zhuanlan.zhihu.com/p/343033661>

| 浮点类型 | 内存占用（位） | 内存分配                           | 指数范围     | 指数偏移 | 范围（约等于）                                                                                  | 精度                                           |
| -------- | -------------- | ---------------------------------- | ------------ | -------- | ----------------------------------------------------------------------------------------------- | ---------------------------------------------- |
| float    | 32             | 1 符号位<br>8 指数位<br>23 尾数位  | [-127, 128]  | +127     | $ [-3.4*10^{38}, -1.18*10^{-38}] $ <br> $ \bigcup $ <br> $ [1.18*10^{-38}, 3.4*10^{38}] $       | 7~8 位有效数字<br>（7 位肯定保证，8 位也存在） |
| double   | 64             | 1 符号位<br>11 指数位<br>52 尾数位 | [-1023, 1024 | +1023    | $ [-1.80*10^{308}, -2.23*10^{-308}] $ <br> $ \bigcup $ <br> $ [2.23*10^{-308}, 1.80*10^{308}] $ | 16-17 位有效数字                               |

下面主要研究 32 位浮点数 (或者说单精度浮点数, 或者说 float 类型) 在计算机中是怎么存储的. 其他精度, 比如 64 位浮点数, 则大同小异.
以一个 32 位浮点数 `20.5` 为例，其占用的 32 个二进制位的内存编号从高到低 (从 31 到 0), 共包含如下几个部分:

| 1bit（符号位） | 8bits（指数位） |       23bits（尾数位）       |
| :------------: | :-------------: | :--------------------------: |
|       1        |    1000 0011    | 0100 1000 0000 0000 0000 000 |

- **sign**: 符号位。
- **biased exponent**: 偏移后的指数位。
- **fraction**: 尾数位。

下面会依次介绍这三个部分的概念, 用途.

1. **符号位: sign**

   符号位: 占据最高位(第 31 位)这一位, 用于表示这个浮点数是正数还是负数, **为 0 表示正数, 为 1 表示负数**。

   举例: 对于十进制数 `20.5`, 存储在内存中时, 符号位应为**0**, 因为这是个**正数**。
   &nbsp;

2. **偏移后的指数位: biased exponent**

   用于表示以 2 位底的指数。用这个指数对尾数进行缩放。对 32 位浮点型其 8 位指数位的二进制可以表示 **256 种状态**, **IEEE754 规定, 指数位用于表示[-127, 128]范围内的指数**。

   指数位部分还要表示表示负数，会让内存解析更加复杂，因此给指数位添加一个**固定的偏移量**，以使指数位中始终都是一个**非负整数**。

   **规定: 在 32 位单精度类型中, 这个偏移量是 127。在 64 位双精度类型中, 偏移量是 1023。**

   举例: 如果你运算后得到的指数是 -10, 那么偏移后, 在指数位中需要表示为: -10 + 127(偏移量) = **117**
   &nbsp;

3. **尾数位:fraction**

   在以二进制格式存储十进制浮点数时, 首先需要把十进制浮点数表示为二进制格式, 还拿十进制数 `20.5` 举例:

   十进制浮点数 `20.5` = 二进制 `10100.1`，然后需要把这个二进制数转换为以 2 为底的指数形式:

   二进制 `10100.1 = 1.01001 * 2^4`

   注意转换时, 对于乘号左边的二进制数**1.01001**, 需要把小数点放在左起第一位和第二位之间，且第一位需要是个非 0 数。这样表示好之后, 其中的**1.01001**就是**尾数。**

   > 用 二进制数 表示 十进制浮点数 时, 表示为 `尾数 * 指数` 的形式, 并把尾数的小数点放在第一位和第二位之间, 然后保证第一位数非 0, 这个处理过程叫做**规范化(normalized)**。

   其中 1.01001 是**尾数**, 而 4 就是**偏移前的指数(unbiased exponent)**, 上文讲过, 32 位单精度浮点数的偏移量(bias)为 127, 所以**偏移后指数(biased exponent)**就是 **4 + 127 = 131**, 131 转换为二进制就是**1000 0011**

   现在还需要对**尾数**做一些特殊处理
   - **隐藏高位 1.**

     你会发现, 尾数部分的最高位始终为**1.** 比如这里的 **1.**01001，这是因为前面说过，规范化之后，尾数中的小数点会位于左起第一位和第二位之间，且第一位是个非 0 数。
     而二进制中, 每一位可取值只有 0 或 1, 如果第一位非 0, 则第一位只能为 1. 所以在存储尾数时, 可以省略前面的 **1.**，只记录尾数中小数点之后的部分, 这样就节约了一位内存. 所以这里只需记录剩余的尾数部分: **01001**

     所以, 以后再提到尾数, 如无特殊说明, 指的其实是隐藏了整数部分**1.** 之后, 剩下的小数部分

   - **低位补 0**

     有时候尾数会不够填满尾数位。比如尾数 01001 不够 23 位，此时需要在**低位补零**, 补齐 23 位。

     之所以在低位补 0, 是因为尾数中存储的本质上是二进制的小数部分, 所以如果想要在不影响原数值的情况下, 填满 23 位, 就需要在低位补零。

     原尾数是: `01001`(不到 23 位)

     补零之后是: `0100 1000 0000 0000 0000 000` (补至 23 位)

## 浮点数的规范化和非规范化

浮点数的存储、**规范化 (normalized)** 和 **非规范化 (denormalized/subnormal)** 是理解浮点数精度和表示范围的核心。下面我一步步为你拆解。

**一、浮点数的存储格式（以 IEEE 754 为例）**

IEEE 754 是最常用的浮点数标准（CPU/GPU 都用它）。以 **32 位 float（单精度）** 为例，它的结构是：

| 位段    | 名称                       | 位数    | 作用                     |
| ------- | -------------------------- | ------- | ------------------------ |
| [31]    | 符号位 (sign)              | 1 bit   | 0 = 正数，1 = 负数       |
| [30:23] | 阶码 (exponent)            | 8 bits  | 表示指数（偏移编码）     |
| [22:0]  | 尾数 (mantissa / fraction) | 23 bits | 表示有效数字（精度部分） |

实际数值公式：

$$V = (-1)^S \times M \times 2^E$$

其中：

- **S** = 符号位
- **M** = 尾数（有效位）
- **E** = 实际指数（经过偏移还原）

**二、规范化数（Normalized Number）**

1. 定义

   在 IEEE754 中，大多数浮点数是 **规范化数**。
   - 阶码部分 ≠ 全 0，也 ≠ 全 1；
   - 隐含一个“首位 1”。

   计算规则：

   $$E = e - Bias \\ M = 1.fraction$$

   其中 `Bias = 127`（对于 float32）
   例如：
   - 阶码 bits = `10000001` (129)
   - 实际指数 = 129 - 127 = 2
   - 尾数 fraction = `0.01000000000000000000000` → `M = 1.01₂ = 1.25`

   最终值：

   $$V = (+1) × 1.25 × 2^2 = 5.0$$

2. 优点
   - 保证最高有效位是 1，从而能充分利用 23 位尾数的精度。
   - 表示范围大：
     单精度能表示大约 $10^{-38} \sim 10^{38}$。

**三、非规范化数（Denormalized / Subnormal Number）**

1. 定义

   当阶码 **全为 0** 时：
   - 不再有隐含的“1”，而是隐含 **0.**
   - 阶码固定为最小值：$E = 1 - Bias$
   - 尾数直接为 fraction 部分（没有首位 1）

   即：

   $$E = 1 - Bias = -126 \\ M = 0.fraction \\ V = (-1)^S × 0.fraction × 2^{-126}$$

   比如：

   ```log
   符号 = 0
   阶码 = 00000000
   尾数 = 00000000000000000000001
   ```

   则：

   $$M = 0.00000000000000000000001_2 = 2^{-23} \\ V = 2^{-23} × 2^{-126} = 2^{-149}$$

   这是 **最小非规范化数**，约等于 $1.4×10^{-45}$。

2. 用途和意义

   非规范化数用于 **平滑地表示接近 0 的非常小的数值**。
   否则，如果只支持规范化数，那么：
   - 最小规范化数为 $1.0 × 2^{-126}$
   - 再小就直接变成 0
     这会产生“**突变 (sudden underflow)**”。

   有了非规范化数后，就可以连续平滑地接近 0。

3. 代价
   - 精度降低：没有“隐含 1”，有效位少一位。
   - 运算更慢：部分硬件用软件模拟（特别是老 CPU）。

**四、什么时候用**

- **正常范围内的浮点数** → 自动规范化存储。
- **非常接近 0 的数**（小于最小规范化数 $≈ 1.18×10^{-38}$） → 自动进入非规范化区间。
- **更小的数**（绝对值 $< 2^{-149}$） → 直接为 0（underflow）。

**IEEE 754 浮点数数轴图**：

```mathematica
                                          ←────────────── IEEE 754 Float 数轴 ─────────────→

      -∞          负规范化区间        负非规范化区间        -0   +0      正非规范化区间        正规范化区间             +∞     NaN(特殊值)
       │───────────────────────│────────────────────────│────│────│────────────────────│────────────────────────│──────│─────────│
Exponent=255        1~254            0 (非零尾数)          0    0       0 (非零尾数)            1~254               255    255
Mantissa=0      任意(隐含1.xxx)       任意(0.xxx)          0    0        任意(0.xxx)         任意(隐含1.xxx)         0     非0
Bias(偏移量): (Bias=127)
  数值范围:
     (-∞)   [-3.4e38, -1.18e-38]  (-1.18e-38, -1.4e-45)   -0  +0   (1.4e-45, 1.18e-38]   [1.18e-38, 3.4e38]       (+∞)   NaN

                  ↑                     ↑                   ↑             ↑                     ↑
           Normalized 区间       Denormalized 区间         零点      Denormalized 区间       Normalized 区间
```

| 区域           | 阶码 (Exponent) | 尾数 (Mantissa) | 代表数值范围         | 特点          |
| -------------- | --------------- | --------------- | -------------------- | ------------- |
| 负规范化区间   | 1~254           | 含隐含 1        | -3.4e38 ~ -1.18e-38  | 主体负数区    |
| 负非规范化区间 | 0（非零尾数）   | 无隐含 1        | -1.18e-38 ~ -1.4e-45 | 接近 0 的负数 |
| -0             | 0               | 0               | -0                   | 特殊符号位    |
| +0             | 0               | 0               | +0                   | 特殊符号位    |
| 正非规范化区间 | 0（非零尾数）   | 无隐含 1        | 1.4e-45 ~ 1.18e-38   | 接近 0 的正数 |
| 正规范化区间   | 1~254           | 含隐含 1        | 1.18e-38 ~ 3.4e38    | 主体正数区    |
| ±∞             | 255, Mantissa=0 | 无意义          | 无穷大               | 溢出结果      |
| NaN            | 255, Mantissa≠0 | 无意义          | 非数值               | 计算错误结果  |

## 浮点数计算精度丢失

浮点数精度丢失的原理主要源于其内部表示方式的限制。下面详细解释一下：

**一、浮点数的内部表示**

浮点数采用 IEEE 754 标准，以 32 位单精度浮点数为例，它由三部分组成：

- 符号位（1 位）
- 指数位（8 位）
- 尾数位（23 位）

这种表示方式本质上是**科学记数法的二进制版本**，形式为：`(-1)^符号位 × 1.尾数 × 2^(指数-127)`。

精度丢失的根本原因是**有限精度表示**，即 23 位尾数只能精确表示有限个数字，当需要表示的数值超出这个精度范围时，就会发生舍入，导致精度丢失。

**二、"大数吃小数"现象**

这是浮点运算中最典型的精度丢失情况：

```cpp
float a = 1000000.0f;  // 大数
float b = 1.0f;        // 小数
float result = a + b;  // 结果仍然是 1000000.0f
```

- 发生原理：
  1. 浮点加法需要先对齐指数（将两数的指数调整到相同）
  2. 小数的尾数会右移很多位来匹配大数的指数
  3. 右移过程中，小数的有效位被移出了 23 位的表示范围
  4. 这些被移出的位被丢弃，小数的贡献消失

- 具体过程：

  ```log
  大数: 1000000.0f
  - 符号: 0, 指数: 19+127=146, 尾数: 11110100001001000000000

  小数: 1.0f
  - 符号: 0, 指数: 0+127=127,  尾数: 00000000000000000000000

  对齐过程:
  1. 指数差 = 146 - 127 = 19
  2. 小数尾数右移19位: 00000000000000000000000 (完全移出)
  3. 加法: 大数尾数 + 0 = 大数尾数
  4. 结果 = 1000000.0f (小数贡献被丢弃)
  ```

**三、其他常见的精度丢失场景**

1. **循环累加误差**：

   ```cpp
   float sum = 0.0f;
   for (int i = 0; i < 10000000; i++) {
       sum += 0.1f;  // 0.1无法精确表示
   }
   // sum != 1000000.0f
   ```

2. **减法抵消**：

   ```cpp
   float a = 1.0000001f;
   float b = 1.0000000f;
   float diff = a - b;  // 可能得到不准确的结果
   ```

**四、解决方案**

1. 使用双精度浮点数（double）提高精度
2. 调整运算顺序，先处理小数再处理大数
3. 使用专门的高精度数学库
4. 对于货币计算等要求精确的场景，使用定点数或整数运算

浮点数的这种特性是计算机数值表示的固有限制，了解这些原理有助于我们编写更可靠的数值计算程序。

## 浮点计算向大数的指数对齐

**一、指数要对齐**

**数学原理**：

- 只有**同一位权**的数字才能直接相加，即个位与个位相加，十位与十位相加。
- 浮点数加减运算实际上是在进行**不同量级数值的科学记数法运算**。

就像我们手工计算：
$$1.23 × 10^6 + 4.56 × 10^3$$
必须先把指数统一才能相加：
$$1.23 × 10^6 + 0.00456 × 10^6 = 1.23456 × 10^6$$
如果不对齐直接把尾数相加是错误的：
$$1.23 + 4.56 = 5.79$$

**二、向大数对齐而不是小数**

向大数对齐而不是小数，有几个重要原因：

1. **避免溢出**

   ```log
   大数指数: 127 (接近最大值)
   小数指数: 100

   向大数对齐: 小数指数 100 → 127 ✓ (安全)
   向小数对齐: 大数指数 127 → 100 ✗ (指数无法表示更大的值)
   ```

2. **最小化精度损失**

   ```log
   情况A: 向大数对齐
   1000000.0 (指数大) + 1.0 (指数小)
   → 1000000.0 + 0.000001 (小数右移，损失精度)
   → 结果仍保持大数的主要数值

   情况B: 向小数对齐 (假设可行)
   1000000.0 (指数大) + 1.0 (指数小)
   → 需要左移大数的尾数，但会超出表示范围
   → 大数的精度完全丢失，这更糟糕
   ```

3. **硬件实现的统一性**

   现代 CPU 的浮点运算单元采用统一规则：**总是向指数较大的数对齐**，这样：
   - 硬件电路设计简单
   - 运算规则明确，无需额外判断
   - 保证运算结果的一致性

**三、总结**

向大数指数对齐是浮点运算的**工程最优解**：

- 避免指数溢出的硬件限制
- 在不可避免的精度丢失中选择较小的损失
- 保持硬件设计的简洁性和一致性

虽然这会导致"大数吃小数"现象，但这是在硬件资源有限的约束下的合理权衡。理解这个原理有助于我们在编程时避开相关的数值陷阱。

## 不同长度的浮点数精度丢失分析

**一、IEEE 754 浮点数格式回顾**

|      类型      | 总位数 | 符号位 | 指数位 | 尾数位 | 有效数字位 |
| :------------: | :----: | :----: | :----: | :----: | :--------: |
|  半精度(half)  |   16   |   1    |   5    |   10   |     11     |
| 单精度(float)  |   32   |   1    |   8    |   23   |     24     |
| 双精度(double) |   64   |   1    |   11   |   52   |     53     |
| 四倍精度(quad) |  128   |   1    |   15   |  112   |    113     |

**二、精度丢失的数学分析**

1. 临界条件

   当两个数的**指数差**超过**有效数字位数**时，小数会完全丢失：

   ```log
   指数差 ≥ 有效数字位数 → 完全精度丢失
   指数差 < 有效数字位数 → 部分精度丢失
   ```

2. 数值范围计算

   对于数值 `A` 和 `B`（A > B），当 `A ≥ B × 2^有效位数` 时发生完全精度丢失。

**三、各类型精度丢失分析**

1. 半精度浮点数 (16 位)
   - 有效位数：11 位
   - **完全丢失阈值**：$大数 ≥ 小数 × 2^11 = 小数 × 2048$
   - **部分丢失阈值**：$大数 ≥ 小数 × 2^1 = 小数 × 2$

   ```cpp
   // 示例
   half a = 1024.0h;
   half b = 0.25h;    // 1024 = 0.25 × 4096 > 0.25 × 2048
   // a + b = 1024.0h (b完全丢失)
   ```

2. 单精度浮点数 (32 位)
   - 有效位数：24 位
   - **完全丢失阈值**：$大数 ≥ 小数 × 2^24 ≈ 小数 × 1.68×10^7$
   - **部分丢失阈值**：$大数 ≥ 小数 × 2^1 = 小数 × 2$

   ```cpp
   // 示例
   float a = 16777216.0f;  // 2^24
   float b = 1.0f;
   // a + b = 16777216.0f (b完全丢失)

   float c = 1000000.0f;
   float d = 1.0f;         // 1000000 < 1 × 2^24，但 > 1 × 2^20
   // c + d 可能有部分精度丢失
   ```

3. 双精度浮点数 (64 位)
   - 有效位数：53 位
   - **完全丢失阈值**：$大数 ≥ 小数 × 2^53 ≈ 小数 × 9.0×10^15$
   - **部分丢失阈值**：$大数 ≥ 小数 × 2^1 = 小数 × 2$

   ```cpp
   // 示例
   double a = 9007199254740992.0;  // 2^53
   double b = 1.0;
   // a + b = 9007199254740992.0 (b完全丢失)
   ```

4. 四倍精度浮点数 (128 位)
   - 有效位数：113 位
   - **完全丢失阈值**：$大数 ≥ 小数 × 2^113 ≈ 小数 × 1.04×10^34$

**四、总结表格**

| 浮点类型 | 有效位数 | 完全丢失阈值 |    十进制近似     |     常见场景      |
| :------: | :------: | :----------: | :---------------: | :---------------: |
|  半精度  |  11 位   | 小数 × 2^11  |   小数 × 2,048    | 图形处理、AI 推理 |
|  单精度  |  24 位   | 小数 × 2^24  | 小数 × 1.68×10^7  |   一般科学计算    |
|  双精度  |  53 位   | 小数 × 2^53  | 小数 × 9.0×10^15  |  高精度科学计算   |
| 四倍精度 |  113 位  | 小数 × 2^113 | 小数 × 1.04×10^34 |   超高精度应用    |

实际应用建议：

1. **金融计算**：使用定点数或专用库
2. **科学计算**：根据数据范围选择合适精度
3. **累加运算**：按数值大小排序，先加小数
4. **比较运算**：使用相对误差而非绝对相等

这些阈值帮助我们在实际编程中预判何时会发生精度丢失，从而选择适当的数值类型和算法策略。

## 浮点数加减乘除的计算原理和过程

浮点数运算比整数运算复杂得多，需要处理指数、尾数的对齐、规格化等多个步骤。

首先回顾 IEEE 754 标准下的浮点数格式：

```log
浮点数 = (-1)^符号位 × (1 + 尾数) × 2^(指数 - 偏移量)
```

以 32 位单精度为例：

- 符号位：1 位
- 指数：8 位（偏移量 127）
- 尾数：23 位（隐含前导 1）

### 一、浮点数加法运算

- **算法步骤**
  1. **处理特殊值**（NaN、无穷大、零）
  2. **指数对齐**
  3. **尾数相加**
  4. **规格化处理**
  5. **舍入处理**

- **详细过程**

  ```log
  === 浮点数加法详细过程演示 float ===

  操作数 A: 12.500000
    二进制: 0 10000010 10010000000000000000000
    符号位: 0, 指数: 130 (实际: 3), 尾数: 0x480000
    实际值: (-1)^0 × 1.480000 × 2^3

  操作数 B: 3.750000
    二进制: 0 10000000 11100000000000000000000
    符号位: 0, 指数: 128 (实际: 1), 尾数: 0x700000
    实际值: (-1)^0 × 1.700000 × 2^1

  步骤分析:
  1. A = 1.101000... × 2^3 (指数127+3=130)
  2. B = 1.111000... × 2^1 (指数127+1=128)
  3. 指数对齐: B右移2位 → 0.01111000... × 2^3
  4. 尾数相加: 1.101000... + 0.01111000... = 10.00010000...
  5. 规格化: 右移1位 → 1.000010000... × 2^4

  结果: 16.250000
    二进制: 0 10000011 00000100000000000000000
    符号位: 0, 指数: 131 (实际: 4), 尾数: 0x020000
    实际值: (-1)^0 × 1.020000 × 2^4

  验证: 12.5 + 3.75 = 16.250000

  === 大数吃小数示例 ===

  大数: 16777216.000000
    二进制: 0 10010111 00000000000000000000000
    符号位: 0, 指数: 151 (实际: 24), 尾数: 0x000000
    实际值: (-1)^0 × 1.000000 × 2^24

  小数: 1.000000
    二进制: 0 01111111 00000000000000000000000
    符号位: 0, 指数: 127 (实际: 0), 尾数: 0x000000
    实际值: (-1)^0 × 1.000000 × 2^0

  分析:
  1. 大数指数: 151, 小数指数: 127
  2. 指数差: 24位
  3. 小数右移24位后完全超出23位尾数范围
  4. 小数贡献为0，结果等于大数

  结果: 16777216.000000
    二进制: 0 10010111 00000000000000000000000
    符号位: 0, 指数: 151 (实际: 24), 尾数: 0x000000
    实际值: (-1)^0 × 1.000000 × 2^24

  验证: 16777216 + 1 = 16777216

  === 手工计算示例 ===
  手工计算过程:
  A: 符号=0, 指数=3, 尾数=0xC80000
  B: 符号=0, 指数=1, 尾数=0xF00000
  B右移2位: 尾数=0x3C0000
  同号相加: 0xC80000 + 0x3C0000 = 0x1040000
  右规格化: 尾数=0x820000, 指数=4
  最终结果: 符号=0, 指数=4, 尾数=0x020000
  ```

### 二、浮点数减法运算

减法本质上是**符号位取反的加法**：

- `A - B = A + (-B)`
- 将 B 的符号位取反，然后执行加法运算

特殊情况处理：

- 相同数相减可能产生**灾难性抵消**
- 需要额外的左规格化步骤

### 三、浮点数乘法运算

- **算法步骤**
  1. **处理特殊值**
  2. **符号位异或**：`sign_result = sign_A ⊕ sign_B`
  3. **指数相加**：`exp_result = exp_A + exp_B`
  4. **尾数相乘**
  5. **规格化处理**
  6. **舍入处理**

  > 异或（XOR）⊕：不同为 1。
  > 同或（XNOR）⊙：相同为 1。

- **浮点数乘法详细过程演示**

  ```log
  === 浮点数乘法详细过程演示 float ===

  操作数 A: 2.500000
    符号: 0, 指数: 128 (实际: 1), 尾数: 1.200000
  操作数 B: 1.500000
    符号: 0, 指数: 127 (实际: 0), 尾数: 1.400000

  计算过程:
  1. 符号位: 0 ⊕ 0 = 0 (正数)
  2. 指数相加: (127+1) + (127+0) - 127 = 128 (实际指数: 1)
  3. 尾数相乘: 1.25 × 1.5 = 1.875
     二进制: 1.010000 × 1.100000 = 1.111000
  4. 结果: 1.875 × 2^1 = 3.75

  结果: 3.750000
    符号: 0, 指数: 128 (实际: 1), 尾数: 1.700000
  验证: 2.5 × 1.5 = 3.75

  === 需要规格化的乘法示例 ===

  操作数 C: 1.750000
    符号: 0, 指数: 127 (实际: 0), 尾数: 1.600000
  操作数 D: 1.750000
    符号: 0, 指数: 127 (实际: 0), 尾数: 1.600000

  计算过程:
  1. 符号位: 0 ⊕ 0 = 0
  2. 指数相加: 127 + 127 - 127 = 127 (实际指数: 0)
  3. 尾数相乘: 1.75 × 1.75 = 3.0625
     二进制: 1.110000 × 1.110000 = 11.000001
  4. 规格化: 11.000001 → 1.1000001 × 2^1
     新指数: 0 + 1 = 1
  5. 结果: 1.1000001 × 2^1 = 3.0625

  结果: 3.062500
    符号: 0, 指数: 128 (实际: 1), 尾数: 1.440000
  验证: 1.75 × 1.75 = 3.0625

  === 手工计算过程 ===
  A: 符号=0, 指数=128, 尾数=0xA00000
  B: 符号=0, 指数=127, 尾数=0xC00000
  1. 符号位: 0 ⊕ 0 = 0
  2. 指数: 128 + 127 - 127 = 128
  3. 尾数乘积: 0x780000000000
  4. 右移23位: 0xF00000
  最终: 符号=0, 指数=128, 尾数=0x700000
  实际计算结果: 3.750000

  === 手工计算过程 ===
  A: 符号=0, 指数=127, 尾数=0xE00000
  B: 符号=0, 指数=127, 尾数=0xE00000
  1. 符号位: 0 ⊕ 0 = 0
  2. 指数: 127 + 127 - 127 = 127
  3. 尾数乘积: 0xC40000000000
  4. 右移23位: 0x1880000
  5. 规格化: 右移1位, 尾数=0xC40000, 指数=128
  最终: 符号=0, 指数=128, 尾数=0x440000
  实际计算结果: 3.062500
  ```

### 四、浮点数除法运算

- **算法步骤**
  1. **处理特殊值**（除零、NaN 等）
  2. **符号位异或**：`sign_result = sign_A ⊕ sign_B`
  3. **指数相减**：`exp_result = exp_A - exp_B + 127`
  4. **尾数相除**
  5. **规格化处理**
  6. **舍入处理**

- **浮点数除法详细过程演示**

  ```log
  === 浮点数除法详细过程演示 float ===

  被除数 A: 7.500000
    符号: 0, 指数: 129 (实际: 2), 尾数: 1.700000
  除数 B: 2.500000
    符号: 0, 指数: 128 (实际: 1), 尾数: 1.200000

  计算过程:
  1. 符号位: 0 ⊕ 0 = 0 (正数)
  2. 指数相减: (127+2) - (127+1) + 127 = 128 (实际指数: 1)
  3. 尾数相除: 1.875 ÷ 1.25 = 1.5
     二进制: 1.111000 ÷ 1.010000 = 1.100000
  4. 结果: 1.5 × 2^1 = 3.0

  结果: 3.000000
    符号: 0, 指数: 128 (实际: 1), 尾数: 1.400000
  验证: 7.5 ÷ 2.5 = 3.0

  === 需要规格化的除法示例 ===

  被除数 C: 1.500000
    符号: 0, 指数: 127 (实际: 0), 尾数: 1.400000
  除数 D: 3.000000
    符号: 0, 指数: 128 (实际: 1), 尾数: 1.400000

  计算过程:
  1. 符号位: 0 ⊕ 0 = 0
  2. 指数相减: 127 - (127+1) + 127 = 126 (实际指数: -1)
  3. 尾数相除: 1.5 ÷ 1.5 = 1.0
  4. 结果: 1.0 × 2^(-1) = 0.5

  结果: 0.500000
    符号: 0, 指数: 126 (实际: -1), 尾数: 1.000000
  验证: 1.5 ÷ 3.0 = 0.5

  === 特殊情况：除零 ===

  被除数: 5.000000
    符号: 0, 指数: 129 (实际: 2), 尾数: 1.200000
  除数 (零): 0.000000 (特殊值)
  结果: +∞ (无穷大)
  5.0 ÷ 0.0 = 1.#INF00

  === 特殊情况：0÷0 ===

  0.0 ÷ 0.0 = NaN (Not a Number)

  === 手工计算过程 ===
  A: 符号=0, 指数=129, 尾数=0xF00000
  B: 符号=0, 指数=128, 尾数=0xA00000
  1. 符号位: 0 ⊕ 0 = 0
  2. 指数: 129 - 128 + 127 = 128
  3. 尾数相除: 0xF00000 ÷ 0xA00000 = 0xC00000
  最终: 符号=0, 指数=128, 尾数=0x400000
  实际计算结果: 3.000000

  === 除零检测 ===
  5.0 ÷ 0 = +无穷大

  === 除零检测 ===
  0 ÷ 0 = NaN
  ```

### 五、运算中的关键问题

1. 规格化处理

   **左规格化**（结果太小）：
   - 尾数左移，指数减 1
   - 直到尾数最高位为 1

   **右规格化**（结果太大）：
   - 尾数右移，指数加 1
   - 直到尾数在正常范围内

2. 舍入模式

   IEEE 754 定义了 4 种舍入模式：
   - **就近偶数舍入**（默认）：舍入到最近的偶数
   - **向零舍入**：截断
   - **向正无穷舍入**：向上舍入
   - **向负无穷舍入**：向下舍入

3. 特殊值处理

   |   操作   | $+∞$ | $-∞$  | $NaN$ |  $0$  |
   | :------: | :--: | :---: | :---: | :---: |
   | $+∞ + x$ | $+∞$ | $NaN$ | $NaN$ | $+∞$  |
   | $+∞ × x$ | $±∞$ | $∓∞$  | $NaN$ | $NaN$ |
   | $+∞ ÷ x$ | $±∞$ | $∓∞$  | $NaN$ | $±∞$  |
   | $x ÷ 0$  | $±∞$ | $±∞$  | $NaN$ | $NaN$ |

### 六、性能优化技术

1. 硬件层面
   - **专用浮点运算单元（FPU）**
   - **流水线处理**
   - **并行乘加运算（FMA）**

2. 算法层面
   - **快速倒数算法**（如 Quake III 中的快速开平方根）
   - **查表法**用于超越函数
   - **CORDIC 算法**用于三角函数

浮点数运算的复杂性在于：

1. **多步骤处理**：每种运算都需要指数处理、尾数运算、规格化等步骤
2. **精度控制**：需要处理舍入误差和精度丢失
3. **特殊值处理**：必须正确处理无穷大、NaN、零等特殊情况
4. **性能权衡**：在精度和速度之间找到平衡

### 七、实际编程中的常见陷阱

```log
=== 陷阱1: 浮点数相等性比较 ===

0.1 + 0.2 = 0.30000001192092896000
0.3       = 0.30000001192092896000
直接比较: a == b ? 相等
为什么? 因为0.1和0.2无法精确表示！

使用误差比较 (epsilon=1e-6): 相等

--- 累加误差 ---
累加10次0.1: 1.00000011920928960000
直接的1.0:   1.00000000000000000000
是否相等? 否

=== 陷阱2: 结合律不成立 ===

a = 1e+020, b = -1e+020, c = 1e+000
(a + b) + c = 1.0
a + (b + c) = 0.0
结果相同? 否

分析:
(a + b) + c: (1e20 - 1e20) + 1 = 0 + 1 = 1
a + (b + c): 1e20 + (-1e20 + 1) = 1e20 + (-1e20) = 0 (1被吃掉)

=== 陷阱3: 分配律不成立 ===

a = 1e+020, b = 1.0, c = -1.0
a * (b + c) = 0.0
(a*b) + (a*c) = 0e+000
结果相同? 是

=== 陷阱4: 灾难性抵消 ===

x = 1.0000000000
y = 0.9999998808
x - y = 1.1920928955e-007
相对误差非常大！

--- 二次方程求根 ---
方程: x² - 200x + 1 = 0
标准公式:
x1 = 199.9949951172
x2 = 0.0049972534
改进公式:
x1 = 0.0049972534
x2 = 200.1099243164 (使用韦达定理)

=== 陷阱5: 上溢和下溢 ===

float最大值: 3.40e+038
float最小正值: 1.18e-038

上溢示例:
1e38 × 10 = 1.#INF00
结果是无穷大: 是

下溢示例:
1e-38 × 1e-10 = 0.00e+000
结果是0: 是

=== 陷阱6: 运算顺序的重要性 ===

数组: [1e10, 1, 1, 1, -1e10]
从左到右求和: 0.0
优化顺序求和: 3.0
正确答案应该是: 3.0

=== 陷阱7: 除法 vs 乘法 ===

x / 3 / 3 / 3 = 0.03703703731298446700
x * (1/3) * (1/3) * (1/3) = 0.03703704103827476500
x / 27 = 0.03703703731298446700
三种方法结果可能不同！

性能提示: 乘法通常比除法快
建议: 预计算倒数，用乘法代替除法

=== 最佳实践总结 ===

1. 比较操作:
   ✗ if (a == b)
   ✓ if (fabs(a - b) < epsilon)

2. 避免减法抵消:
   ✗ b² - 4ac 当判别式接近0
   ✓ 使用数值稳定的算法

3. 累加顺序:
   ✗ 大数和小数混合累加
   ✓ 先排序，从小到大累加

4. 选择合适精度:
   • 一般计算: float (32位)
   • 科学计算: double (64位)
   • 金融计算: 整数或定点数

5. 注意运算顺序:
   • 浮点运算不满足结合律和分配律
   • 调整运算顺序可以提高精度

6. 避免溢出:
   • 大数运算前先判断范围
   • 使用对数运算处理极大/极小值
```

### 八、高级优化技术

1. **融合乘加（FMA）指令**

   现代处理器支持 FMA 指令，可以在一个操作中完成 `a × b + c`：

   ```cpp
   // 普通方式（两次舍入）
   float result = a * b + c;  // 先乘法舍入，再加法舍入

   // FMA方式（一次舍入，更精确）
   float result = fmaf(a, b, c);  // 只在最后舍入一次
   ```

   **优势**：
   - 减少舍入误差
   - 提高运算速度
   - 在矩阵运算中特别有用

2. **快速倒数平方根**

   经典的 Quake III 算法：

   ```cpp
   float fast_inverse_sqrt(float x) {
       float xhalf = 0.5f * x;
       int i = *(int*)&x;           // 将float解释为int
       i = 0x5f3759df - (i >> 1);   // 神奇的常数
       x = *(float*)&i;             // 转回float
       x = x * (1.5f - xhalf * x * x); // 牛顿迭代
       return x;
   }
   ```

   这个算法巧妙利用了浮点数的内部表示，速度远快于标准库函数。

3. **数值稳定性技巧**

   **Kahan 求和算法**（补偿求和）：

   ```cpp
   float kahan_sum(float *array, int n) {
       float sum = 0.0f;
       float c = 0.0f;  // 补偿值

       for (int i = 0; i < n; i++) {
           float y = array[i] - c;
           float t = sum + y;
           c = (t - sum) - y;  // 捕获丢失的精度
           sum = t;
       }
       return sum;
   }
   ```

### 九、浮点数运算的硬件实现

1. 流水线结构

   现代 FPU 采用流水线设计：

   ```log
   阶段1: 指数对齐
   阶段2: 尾数运算
   阶段3: 规格化
   阶段4: 舍入
   阶段5: 结果输出
   ```

2. 并行处理

   **SIMD 指令**（如 SSE、AVX）可以同时处理多个浮点数：

   ```cpp
   // 标量操作
   for (int i = 0; i < 4; i++) {
       c[i] = a[i] + b[i];
   }

   // SIMD操作（伪代码）
   __m128 va = _mm_load_ps(a);
   __m128 vb = _mm_load_ps(b);
   __m128 vc = _mm_add_ps(va, vb);  // 一次处理4个float
   _mm_store_ps(c, vc);
   ```

### 十、不同应用场景的选择

1. 实时图形渲染
   - 使用半精度(float16)节省带宽
   - 利用 GPU 的并行浮点运算能力
   - 可以容忍一定的精度损失

2. 科学计算
   - 使用双精度(double)保证精度
   - 采用数值稳定的算法
   - 关注条件数和误差传播

3. 机器学习
   - 训练: 使用 float32 或 mixed precision
   - 推理: 可降至 float16 甚至 int8
   - 批量归一化减少数值问题

4. 金融计算
   - **避免使用浮点数**
   - 使用整数表示（如：分为单位）
   - 或使用专门的定点数库

### 完整的运算对比表

| 运算 |  指数处理  | 尾数处理 | 特殊要求 | 相对速度 |
| :--: | :--------: | :------: | :------: | :------: |
| 加法 | 对齐到大数 |   相加   |  规格化  |    快    |
| 减法 | 对齐到大数 |   相减   | 左规格化 |    快    |
| 乘法 |    相加    |   相乘   | 可能溢出 |   中等   |
| 除法 |    相减    |   相除   | 复杂算法 |    慢    |

### 总结

浮点数运算的核心原理可以归纳为：

1. **表示限制**：有限位数导致精度有限
2. **对齐需求**：加减法需要指数对齐
3. **规格化**：保持标准形式
4. **舍入误差**：不可避免的精度损失
5. **特殊值**：需要正确处理边界情况

理解这些原理后，我们可以：

- 预测和避免数值问题
- 选择合适的算法和数据类型
- 编写更高效、更可靠的代码
- 在精度和性能之间做出正确权衡

浮点数运算是计算机科学中精妙而复杂的领域，掌握其原理对于编写高质量的数值计算程序至关重要。

## 精度说明

浮点数的精确度是按照**整体有效位数来的，并不是只是考虑小数部分**。

**float 的精度为 7~8 位有效数字**（7 位肯定能保证，8 位的值也存在），而不是 7 位小数。

**double 的精度为 16~17 位有效数字**。

看一段代码

```java
public class Main {

    public static void main(String[] args) {
        float f6 = 1.000003f;//6位小数位,总共7位
        float f7 = 1.0000003f;//7位小数位，总共8位
        float f8 = 1.00000003f;//8位小数位，总共9位
        float f_8 = 10.000003f;//6位小数位,总共8位
        float f_9 = 10.0000003f;//7位小数位,总共9位
        float f_10 = 10.00000003f;//8位小数位,总共10位

        double d15 = 1.000000000000003;//15位小数位，总共16位
        double d16 = 1.0000000000000003;//16位小数位，总共17位
        double d17 = 1.00000000000000003;//17位小数位，总共18位
        double d_17 = 10.000000000000003;//15位小数位，总共17位
        double d_18 = 10.0000000000000003;//16位小数位，总共18位
        double d_19 = 10.00000000000000003;//17位小数位，总共19位

        System.out.println("结果为false证明 == 校验到了小数点位, 精确度可信");
        System.out.println("float(7位有效,6位小数)    1.000003f  == 1           的结果是：" + (f6==1));
        System.out.println("float(8位有效,7位小数)    1.0000003f == 1           的结果是：" + (f7==1));
        System.out.println("float(9位有效,8位小数)    1.00000003f  == 1         的结果是：" + (f8==1));
        System.out.println("float(8位有效,6位小数)    10.000003f  == 10         的结果是：" + (f_8==10));
        System.out.println("float(9位有效,7位小数)    10.0000003f  == 10        的结果是：" + (f_9==10));
        System.out.println("float(10位有效,8位小数)   10.00000003f  == 10       的结果是：" + (f_10==10));
        System.out.println("------------------");

        System.out.println("double(16位有效,15位小数) 1.000000000000003 == 1    的结果是：" + (d15==1));
        System.out.println("double(17位有效,16位小数) 1.0000000000000003 == 1   的结果是：" + (d16==1));
        System.out.println("double(18位有效,17位小数) 1.00000000000000003 == 1  的结果是：" + (d17==1));
        System.out.println("double(17位有效,15位小数) 10.000000000000003 == 10  的结果是：" + (d_17==10));
        System.out.println("double(18位有效,16位小数) 10.0000000000000003 == 10 的结果是：" + (d_18==10));
        System.out.println("double(19位有效,17位小数) 10.00000000000000003 == 10的结果是：" + (d_19==10));
    }
}
```

![img](https://i-blog.csdnimg.cn/blog_migrate/356fc47b10a75ce1b7582e74f3118135.png)

结果为 false 的，那么小数点存在有意义，也就是精确位。从结果来看，float 可以精确到有效数字 8 位， double 到了 17 位。

> 上文为简单直接使用 `==` 比较浮点数大小，实际请不要采用这种方法。
> 不可将浮点变量用 `==` 或 `！=` 与任何数字比较。因为有些浮点数是近似存储的，且计算机会把精度之外的小数部分截断，导致判断结果不可靠。
> 解决方案：定义一个精度，用差的绝对值比较，差值在精度范围内就认为是相等的。

## 大模型中常用浮点数

彻底搞懂 float16 与 float32 的计算方式：<https://blog.csdn.net/leo0308/article/details/117398166>

**大模型精度（FP16，FP32，BF16）详解与实践**:<https://www.53ai.com/news/qianyanjishu/2024052494875.html>

FP16 与 BF16 区别:<https://transformerswsz.github.io/2024/05/05/FP16%E4%B8%8EBF16%E5%8C%BA%E5%88%AB/>

[那些年，AI 芯片里的浮点(FloatPoint)格式](https://zhuanlan.zhihu.com/p/449857213)

[Understanding Data Types in AI and HPC: Int8, FP8, FP16, BF16, BF32, FP32, TF32, FP64, and Hardware Accelerators](https://itsabout.ai/understanding-data-types-in-ai-and-hpc-int8-fp8-fp16-bf16-bf32-fp32-tf32-fp64-and-hardware-accelerators/)

## 浮点数的round模式
